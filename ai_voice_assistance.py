# -*- coding: utf-8 -*-
"""AI Voice ASSISTANCE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fDX70xGRha0_pst_7z4ztlCXXQg25zew
"""

!pip install gtts

!pip install nest_asyncio

!pip install openai-whisper

!pip install whisper transformers edge-tts webrtcvad pydub

from transformers import pipeline
import asyncio
import webrtcvad
import wave
from gtts import gTTS
import whisper
from edge_tts import Communicate

def voice_to_text(audio_file_path):
    model = whisper.load_model("base")
    transcription = model.transcribe(audio_file_path)
    text = transcription["text"]
    return text

# Step 2: Text Input into LLM
def text_to_llm_response(text):
    llm = pipeline("text-generation", model="gpt2")
    response = llm(text, max_length=50, num_return_sequences=1)[0]['generated_text']
    return response

# Text-to-Speech Conversion with Tunable Parameters
async def text_to_speech_with_params(text, output_path, voice="en-US-JennyNeural",rate="+10%"):
    communicate = Communicate(text=text, voice=voice, rate=rate)
    await communicate.save(output_path)

# Apply VAD to Detect Speech
def apply_vad(audio_file_path):
    vad = webrtcvad.Vad()
    vad.set_mode(1)  # Aggressiveness mode
    with wave.open(audio_file_path, 'rb') as wf:
        frames = wf.readframes(wf.getnframes())
        sample_rate = wf.getframerate()
        frame_duration = 20  # ms
        for i in range(0, len(frames), int(sample_rate * frame_duration / 1000)):
            frame = frames[i:i + int(sample_rate * frame_duration / 1000)]
            if vad.is_speech(frame, sample_rate):
                yield frame

# Additional Features: Restrict Output Length
def restrict_output_length(text, max_sentences=2):
    sentences = text.split('. ')
    return '. '.join(sentences[:max_sentences]) + '.'

# Example usage
text = voice_to_text('/content/temp_audio (1).wav')
print(text)

response = text_to_llm_response(text)
response = restrict_output_length(response)
print(response)

import nest_asyncio
import asyncio

# Patch the running event loop
nest_asyncio.apply()

# Use await if you're in a Jupyter notebook or similar environment
await text_to_speech_with_params(response, "output.mp3", voice='en-GB-RyanNeural', rate="+10%")







